# üß∞ My Working Stack

## üñ•Ô∏è Programming & Query Languages

These are the core languages I use to build, automate, and model solutions ‚Äî from semantic layers to scripting to interface design.

- **Python** ‚Äî scripting, automation, data analysis, scraping, and integration
- **SQL** ‚Äî querying, transformation, and modeling across BI and backend systems
- **DAX** ‚Äî advanced measure creation and expression logic for Power BI models
- **Power Query (M)** ‚Äî data transformation and shaping inside Power BI
- **TMDL** ‚Äî semantic modeling and deployment for enterprise-scale tabular models
- **Lua** ‚Äî daily use for customizing and extending my Neovim configuration (via LazyVim)
- **C#** ‚Äî scripting in Tabular Editor for DAX automation and metadata handling
- **JavaScript** ‚Äî used for scripting in workflow automation and custom widgets
- **HTML/CSS** ‚Äî used for styling and customizing visual elements in web-based reports and dashboards

## üìä Data Tools & BI Platforms

These are the primary platforms and tools I use to design, deploy, and maintain enterprise-ready BI and reporting solutions.

- **Power BI** ‚Äî my core platform for report development, modeling, and insight delivery

  - **Power BI Desktop** ‚Äî for model design, data transformation (Power Query), and report layout
  - **Power BI Service** ‚Äî for dataset publishing, dataflows, pipelines, row-level security, and workspace management

- **Microsoft Fabric** ‚Äî early adopter of Fabric as a unified analytics platform

  - Working with **Lakehouses**, **Warehouses**, **Pipelines**, and **Semantic Models** (via TMDL)

- **Tabular Editor** ‚Äî used for advanced semantic modeling, automation, and deployment

  - Authoring and editing TMDL or Tabular Object Model (TOM)
  - Scripting with C# for model manipulation and optimization
  - Managing calculation groups, translations, metadata, and source control

- **DAX Studio** ‚Äî essential for performance tuning, diagnostics, and query inspection

  - Evaluating DAX query plans and storage engine behavior
  - Measuring performance with Server Timings and Query Plan
  - Testing and refining DAX expressions in isolation

- **Excel** ‚Äî often used for rapid validation, ad hoc data profiling, and business-oriented modeling
  - Verifying model output via pivot tables connected to datasets
  - Creating sanity checks and reconciliation reports
  - Supporting hybrid workflows with non-technical users

## ü§ñ AI, LLMs & Automation

I actively integrate AI tooling into my workflows ‚Äî both to accelerate development and to create intelligent, adaptable systems for clients and internal use.

- **Prompt Engineering** ‚Äî designing modular, context-aware prompts for analysis, content creation, automation, and structured logic chains

- **LLM Tooling** ‚Äî working across multiple platforms for prototyping, insight generation, and workflow integration:

  - **OpenAI** ‚Äî for structured prompt systems, content extraction, and assistant-style interfaces
  - **Microsoft Copilot** ‚Äî for productivity acceleration across documentation and reporting tools
  - **Ollama** ‚Äî experimenting with lightweight, private LLMs for offline and local-enhanced tasks

- **Generative AI** ‚Äî using LLMs for interface sketching, documentation scaffolding, semantic tagging, and rapid knowledge transfer

- **AI-Augmented Workflows** ‚Äî supporting tasks like data profiling, column descriptions, metric definitions, text-to-query translation, and QA/testing scenarios

- **RAG and Vector Search (Exploratory)** ‚Äî experimenting with semantic search, FAISS/Qdrant vector stores, and structured context injection

- **Automation Integration** ‚Äî embedding LLMs into terminal workflows, scripts, and custom tools to reduce boilerplate, lookup effort, and repetitive coding

I focus on using AI to support **human-led problem solving** ‚Äî not to replace thinking, but to reduce friction, amplify insights, and enable faster, more confident execution.
